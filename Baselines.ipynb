{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "For now we are going to be using Jigsaw as the dataset"
   ],
   "metadata": {
    "id": "Qu2TrI1vu2to"
   },
   "id": "Qu2TrI1vu2to"
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install datasets"
   ],
   "metadata": {
    "collapsed": true,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GRe1gFSzu9Rw",
    "outputId": "7bdc6841-af47-4c60-cfc0-29af766333b9"
   },
   "id": "GRe1gFSzu9Rw",
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.36.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2026.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install -q scikit-learn datasets torch fasttext-wheel psutil"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yPN1OHgCvoyU",
    "outputId": "6e9b9375-0d57-45c0-c235-710199a41162"
   },
   "id": "yPN1OHgCvoyU",
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[?25l   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m0.0/4.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m\u2501\u2501\u001b[0m\u001b[91m\u2578\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m0.3/4.6 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[90m\u257a\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m2.4/4.6 MB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[91m\u2578\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[?25l   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m0.0/293.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m293.6/293.6 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import time\n",
    "import psutil\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datasets import load_dataset\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "id": "bDi-FLEdvBEo"
   },
   "id": "bDi-FLEdvBEo",
   "execution_count": 36,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data\n",
    "\n",
    "Overall, we take the bare Jigsaw comment classification, the only changes are:\n",
    "\n",
    "- we only take the 0 or 1 toxicity scores, -1 and nans are invalidated\n",
    "- we trim the comments at max_lenth = 1500 and we ignore comments shorter than 20 chars"
   ],
   "metadata": {
    "id": "BD0BaInb1vT0"
   },
   "id": "BD0BaInb1vT0"
  },
  {
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "train = load_dataset(\"thesofakillers/jigsaw-toxic-comment-classification-challenge\", split=\"train\")\n",
    "# test  = load_dataset(\"thesofakillers/jigsaw-toxic-comment-classification-challenge\", split=\"test\")"
   ],
   "metadata": {
    "id": "NO4hXVy6u2j1"
   },
   "id": "NO4hXVy6u2j1",
   "execution_count": 32,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train = train.filter(lambda x: x[\"comment_text\"] is not None)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "15825fc6ffa348e3928177f281e41957",
      "f0e117b7569044d2a542c2687ea9c6cf",
      "8735f0e0dd5444c0b90b2c0728c2db4c",
      "0412c8ecec564ee4aa862c4e87b1870c",
      "efb44937fa504f5d8fc7df16e81f4458",
      "f31a9e5987bf44248feb05282a6b9010",
      "3c0d43b1a4e14525bf0ef5c102092c3d",
      "9e6e5ecdfa6b497aa44de029dd344822",
      "5496cf34bc144d3faf87986c8772ddd3",
      "edfedd1ce1034ab3aaa3fb8d91c60199",
      "6c93d64bb3fb42d7affd7afc7380b4cb"
     ]
    },
    "id": "j7iaVyZB0_Pb",
    "outputId": "7f1c5011-d66e-48b9-b321-f8fda0e56b6c"
   },
   "id": "j7iaVyZB0_Pb",
   "execution_count": 33,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Filter:   0%|          | 0/159571 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "15825fc6ffa348e3928177f281e41957"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "train = train.filter(lambda x: len(x[\"comment_text\"]) >= 20)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "4f75b40593ec4d7b85ed1250f4650d19",
      "c1372ddf8cfb4a60bd8b99e496403d48",
      "46b63d1b20d04954a82e6bdb4aeaf812",
      "b4836f1ae41f4f948cf556dc693c72f5",
      "1c13bec126f2438db05c8830d59ed4cf",
      "ac71e83090fe4faea7b87b33b5b39e42",
      "c9459621b65142b38341cc26842b7825",
      "5ab9264db42641d9b8343435adbbc096",
      "c8a2b7ede5ab44c5abce7f04fa957f68",
      "777c8c630c45495a8c21ac0d6eca9f6e",
      "ec44e0fc7d414760a32fe09249f0d62e"
     ]
    },
    "id": "N9FXKTHy0z3-",
    "outputId": "0844c8f9-2bee-46dc-808e-fe3a931f5620"
   },
   "id": "N9FXKTHy0z3-",
   "execution_count": 34,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Filter:   0%|          | 0/159571 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4f75b40593ec4d7b85ed1250f4650d19"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "train = train.map(\n",
    "    lambda x: {\"comment_text\": x[\"comment_text\"].strip()}\n",
    ")\n",
    "\n",
    "MAX_LEN = 1500\n",
    "\n",
    "def trim(example):\n",
    "    text = example[\"comment_text\"]\n",
    "    return {\"comment_text\": text if len(text) <= MAX_LEN else text[:MAX_LEN]}\n",
    "\n",
    "train = train.map(trim)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "c70d34dc384c4d41b60328391c46e801",
      "8919bcc16c144e5fb423067a8c350b24",
      "5eedd179263a4c66938eb7ee5dfc6cd0",
      "99f4fbacf4da4927b20ca22766b2abb1",
      "d20b226d46014d74986e7037414f4c73",
      "b80091b1cfba4a878a4b3fab1548634e",
      "664e867d7cf64e3fb48404ddf574736f",
      "5aee43906f3a47d3a25611a2895ffb67",
      "680b2bdfcfe249a885294d71145b084f",
      "5466705676504a4fb7f929da1cbcad39",
      "3cee8b5559b4480b88e403c4e705dfd2",
      "af2ba6fc0ef845099765270b3f2a37c3",
      "6da4769e08a04334b2c3cd2dd88efde3",
      "a1a916932a7a494baa4a61e0e41ad5ad",
      "99b907d3f3694799902a7835228e1237",
      "845366cbfefe4d539a6bf709f552088a",
      "f0f9b8f566104d878104d5465158a7f3",
      "19f8fe71fb0b44b3abdb59773766b0c6",
      "e6bb56959ce14136b99e54fb7c9df5c9",
      "67a48b1a53c34e70a5a165acdda75256",
      "308d68054a8747e08b04f760c32722bc",
      "0860d924b1ca484b9bae291e7d7c7571"
     ]
    },
    "id": "881Px9KG1HC-",
    "outputId": "ee9aa5b5-9a4e-4730-b59b-8b0fd7f591b9"
   },
   "id": "881Px9KG1HC-",
   "execution_count": 35,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/159287 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c70d34dc384c4d41b60328391c46e801"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/159287 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "af2ba6fc0ef845099765270b3f2a37c3"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "X = np.array(train[\"comment_text\"])\n",
    "y = np.array(train[\"toxic\"]).astype(int)"
   ],
   "metadata": {
    "id": "XaAs_8995BBl"
   },
   "id": "XaAs_8995BBl",
   "execution_count": 44,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=1337,\n",
    "    stratify=y\n",
    ")"
   ],
   "metadata": {
    "id": "6BGl8syUuyqU"
   },
   "id": "6BGl8syUuyqU",
   "execution_count": 47,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "len(X_train)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4hAtR2b95McE",
    "outputId": "e6876877-dc57-4344-cd8e-65e90c7a5107"
   },
   "id": "4hAtR2b95McE",
   "execution_count": 48,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "127429"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "len(y_train)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mtcCc1ZS5OG4",
    "outputId": "b4c1a73d-a1ae-4bf7-f74f-72d0838ba67b"
   },
   "id": "mtcCc1ZS5OG4",
   "execution_count": 49,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "127429"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "len(X_test)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eDHtDffX3MX_",
    "outputId": "fb507477-f57d-47f5-8d3b-fc49cdbf85df"
   },
   "id": "eDHtDffX3MX_",
   "execution_count": 50,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "31858"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "len(y_test)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uenNAxgY3Dmv",
    "outputId": "c8b90542-1b5e-4695-f3a1-b4979dad0012"
   },
   "id": "uenNAxgY3Dmv",
   "execution_count": 51,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "31858"
      ]
     },
     "metadata": {},
     "execution_count": 51
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def measure_latency(model, X, predict_fn, n_runs=5000):\n",
    "    times = []\n",
    "    for i in range(n_runs):\n",
    "        x = X[i % len(X)]\n",
    "        start = time.perf_counter()\n",
    "        predict_fn(model, x)\n",
    "        times.append(time.perf_counter() - start)\n",
    "\n",
    "    times = np.array(times) * 1000  # ms\n",
    "    return {\n",
    "        \"mean_ms\": times.mean(),\n",
    "        \"p95_ms\": np.percentile(times, 95),\n",
    "        \"throughput_msg_s\": 1000 / times.mean()\n",
    "    }\n"
   ],
   "metadata": {
    "id": "zmB_kBtxv3is"
   },
   "id": "zmB_kBtxv3is",
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def model_size_mb(obj):\n",
    "    import pickle, tempfile\n",
    "    with tempfile.NamedTemporaryFile(delete=False) as f:\n",
    "        pickle.dump(obj, f)\n",
    "        size = os.path.getsize(f.name)\n",
    "    return size / (1024 * 1024)"
   ],
   "metadata": {
    "id": "8G-Ozcdlv5An"
   },
   "id": "8G-Ozcdlv5An",
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def linear_flops(nnz):\n",
    "    # dot product: nnz mults + (nnz - 1) adds\n",
    "    return 2 * nnz"
   ],
   "metadata": {
    "id": "S5r2vlYKv7JG"
   },
   "id": "S5r2vlYKv7JG",
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Baseline 1 \u2014 BoW + Logistic Regression"
   ],
   "metadata": {
    "id": "5e4V-JwYwL1X"
   },
   "id": "5e4V-JwYwL1X"
  },
  {
   "cell_type": "code",
   "source": [
    "bow = CountVectorizer(\n",
    "    max_features=100_000,\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=5\n",
    ")\n",
    "\n",
    "Xtr = bow.fit_transform(X_train)\n",
    "Xte = bow.transform(X_test)\n",
    "\n",
    "lr = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    n_jobs=-1\n",
    ")\n",
    "lr.fit(Xtr, y_train)\n",
    "\n",
    "probs = lr.predict_proba(Xte)[:, 1]\n",
    "roc_bow = roc_auc_score(y_test, probs)"
   ],
   "metadata": {
    "id": "2rYSc2ONv9dA"
   },
   "id": "2rYSc2ONv9dA",
   "execution_count": 52,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def bow_predict(model, text):\n",
    "    x = bow.transform([text])\n",
    "    return model.predict_proba(x)[0, 1]\n",
    "\n",
    "lat_bow = measure_latency(lr, X_test, bow_predict)\n",
    "avg_nnz = Xtr.nnz / Xtr.shape[0]\n",
    "flops_bow = linear_flops(avg_nnz)"
   ],
   "metadata": {
    "id": "KEMCBCKHwObY"
   },
   "id": "KEMCBCKHwObY",
   "execution_count": 53,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(f'BOW + LR ROC_AUC = {roc_bow}')\n",
    "print(f'BOW + LR Latency = {lat_bow}')\n",
    "print(f'BOW + LR FLOPS = {flops_bow}')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZnC4_gss2fRD",
    "outputId": "5b9cfa8c-bf31-4889-e5e2-ea45cae287cd"
   },
   "id": "ZnC4_gss2fRD",
   "execution_count": 54,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "BOW + LR ROC_AUC = 0.9521565233043973\n",
      "BOW + LR Latency = {'mean_ms': np.float64(1.3387594617972354), 'p95_ms': np.float64(5.011783050053964), 'throughput_msg_s': np.float64(746.9601736054487)}\n",
      "BOW + LR FLOPS = 144.93134215916314\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Baseline 2 \u2014 TF-IDF + Linear SVM"
   ],
   "metadata": {
    "id": "5vCPJQBvwQka"
   },
   "id": "5vCPJQBvwQka"
  },
  {
   "cell_type": "code",
   "source": [
    "tfidf = TfidfVectorizer(\n",
    "    max_features=100_000,\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=5,\n",
    "    sublinear_tf=True\n",
    ")\n",
    "\n",
    "Xtr = tfidf.fit_transform(X_train)\n",
    "Xte = tfidf.transform(X_test)\n",
    "\n",
    "svm = LinearSVC()\n",
    "svm.fit(Xtr, y_train)\n",
    "\n",
    "scores = svm.decision_function(Xte)\n",
    "roc_svm = roc_auc_score(y_test, scores)"
   ],
   "metadata": {
    "id": "V_aVXdRZwPUq"
   },
   "id": "V_aVXdRZwPUq",
   "execution_count": 55,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def svm_predict(model, text):\n",
    "    x = tfidf.transform([text])\n",
    "    return model.decision_function(x)[0]\n",
    "\n",
    "lat_svm = measure_latency(svm, X_test, svm_predict)\n",
    "avg_nnz = Xtr.nnz / Xtr.shape[0]\n",
    "flops_svm = linear_flops(avg_nnz)"
   ],
   "metadata": {
    "id": "McQ7uT_UwTrB"
   },
   "id": "McQ7uT_UwTrB",
   "execution_count": 56,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(f'ROC_AUC = {roc_svm}')\n",
    "print(f'Latency = {lat_svm}')\n",
    "print(f'FLOPS = {flops_svm}')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "piGJYETY7PFY",
    "outputId": "135a0403-9fc2-4341-817c-d56d6de518ab"
   },
   "id": "piGJYETY7PFY",
   "execution_count": 57,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ROC_AUC = 0.9701528507562371\n",
      "Latency = {'mean_ms': np.float64(1.9603527394000593), 'p95_ms': np.float64(5.752878550083551), 'throughput_msg_s': np.float64(510.1122771945814)}\n",
      "FLOPS = 144.93134215916314\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Baseline 3 \u2014 Character n-gram Logistic Regression"
   ],
   "metadata": {
    "id": "ImNrACnnwVUQ"
   },
   "id": "ImNrACnnwVUQ"
  },
  {
   "cell_type": "code",
   "source": [
    "char_vec = TfidfVectorizer(\n",
    "    analyzer=\"char\",\n",
    "    ngram_range=(3, 5),\n",
    "    max_features=200_000,\n",
    "    min_df=5\n",
    ")\n",
    "\n",
    "Xtr = char_vec.fit_transform(X_train)\n",
    "Xte = char_vec.transform(X_test)\n",
    "\n",
    "char_lr = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    n_jobs=-1\n",
    ")\n",
    "char_lr.fit(Xtr, y_train)\n",
    "\n",
    "probs = char_lr.predict_proba(Xte)[:, 1]\n",
    "roc_char = roc_auc_score(y_test, probs)"
   ],
   "metadata": {
    "id": "vYRv-_HkwUVn"
   },
   "id": "vYRv-_HkwUVn",
   "execution_count": 58,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def char_predict(model, text):\n",
    "    x = char_vec.transform([text])\n",
    "    return model.predict_proba(x)[0, 1]\n",
    "\n",
    "lat_char = measure_latency(char_lr, X_test, char_predict)\n",
    "avg_nnz = Xtr.nnz / Xtr.shape[0]\n",
    "flops_char = linear_flops(avg_nnz)"
   ],
   "metadata": {
    "id": "HLaAIqOxwYUp"
   },
   "id": "HLaAIqOxwYUp",
   "execution_count": 59,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(f'ROC_AUC = {roc_char}')\n",
    "print(f'Latency = {lat_char}')\n",
    "print(f'FLOPS = {flops_char}')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ShRe6cvN7fU4",
    "outputId": "74091a38-9a48-41cf-bcea-38c696751408"
   },
   "id": "ShRe6cvN7fU4",
   "execution_count": 60,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ROC_AUC = 0.9747515128352414\n",
      "Latency = {'mean_ms': np.float64(2.1315872014129127), 'p95_ms': np.float64(5.7825506003609926), 'throughput_msg_s': np.float64(469.13398585671496)}\n",
      "FLOPS = 1497.0243351199492\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Baseline 4 \u2014 FastText-Style Neural Model"
   ],
   "metadata": {
    "id": "4uMtgM-kwZW6"
   },
   "id": "4uMtgM-kwZW6"
  },
  {
   "cell_type": "code",
   "source": [
    "from collections import Counter\n",
    "\n",
    "def tokenize(text):\n",
    "    return text.lower().split()\n",
    "\n",
    "counter = Counter()\n",
    "for t in X_train:\n",
    "    counter.update(tokenize(t))\n",
    "\n",
    "vocab = {w:i+1 for i,(w,_) in enumerate(counter.most_common(50_000))}"
   ],
   "metadata": {
    "id": "Gu25hT0zwbWz"
   },
   "id": "Gu25hT0zwbWz",
   "execution_count": 61,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class FastText(nn.Module):\n",
    "    def __init__(self, vocab_size, dim=100):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, dim, padding_idx=0)\n",
    "        self.fc = nn.Linear(dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        emb = self.emb(x)\n",
    "        pooled = emb.mean(dim=1)\n",
    "        return self.fc(pooled).squeeze(1)"
   ],
   "metadata": {
    "id": "evoElDlpwhWo"
   },
   "id": "evoElDlpwhWo",
   "execution_count": 62,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def encode(text, max_len=100):\n",
    "    ids = [vocab.get(w, 0) for w in tokenize(text)[:max_len]]\n",
    "    return ids + [0] * (max_len - len(ids))\n",
    "\n",
    "Xtr = torch.tensor([encode(t) for t in X_train[:200_000]])\n",
    "ytr = torch.tensor(y_train[:200_000]).float()\n",
    "\n",
    "model = FastText(len(vocab)+1)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "for epoch in range(3):\n",
    "    opt.zero_grad()\n",
    "    out = model(Xtr)\n",
    "    loss = loss_fn(out, ytr)\n",
    "    loss.backward()\n",
    "    opt.step()"
   ],
   "metadata": {
    "id": "WFbw_GiGwiL_"
   },
   "id": "WFbw_GiGwiL_",
   "execution_count": 63,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "Xte = torch.tensor([encode(t) for t in X_test[:20_000]])\n",
    "with torch.no_grad():\n",
    "    probs = torch.sigmoid(model(Xte)).numpy()\n",
    "\n",
    "roc_ft = roc_auc_score(y_test[:20_000], probs)"
   ],
   "metadata": {
    "id": "4tXGyUWXwjBI"
   },
   "id": "4tXGyUWXwjBI",
   "execution_count": 64,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def ft_predict(model, text):\n",
    "    x = torch.tensor([encode(text)])\n",
    "    with torch.no_grad():\n",
    "        return torch.sigmoid(model(x)).item()\n",
    "\n",
    "lat_ft = measure_latency(model, X_test, ft_predict)\n",
    "flops_ft = 2 * 100 * Xtr.shape[1]  # L * d"
   ],
   "metadata": {
    "id": "b272HVlNwjm0"
   },
   "id": "b272HVlNwjm0",
   "execution_count": 65,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(f'ROC_AUC = {roc_ft}')\n",
    "print(f'Latency = {lat_ft}')\n",
    "print(f'FLOPS = {flops_ft}')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LHx2VV387jOE",
    "outputId": "04e9621f-beae-45a4-d23a-96f94db43b52"
   },
   "id": "LHx2VV387jOE",
   "execution_count": 66,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ROC_AUC = 0.42390666223454476\n",
      "Latency = {'mean_ms': np.float64(0.2431024892019195), 'p95_ms': np.float64(0.3371620497091499), 'throughput_msg_s': np.float64(4113.4914055503805)}\n",
      "FLOPS = 20000\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Baseline 5 \u2014 Toxic-BERT"
   ],
   "metadata": {
    "id": "lApCjFFMw7Y8"
   },
   "id": "lApCjFFMw7Y8"
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install transformers detoxify"
   ],
   "metadata": {
    "collapsed": true,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JOrxL_pzxAkP",
    "outputId": "f5f095e3-5841-487b-d888-35147f29312e"
   },
   "id": "JOrxL_pzxAkP",
   "execution_count": 67,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\n",
      "Collecting detoxify\n",
      "  Downloading detoxify-0.5.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from detoxify) (2.9.0+cpu)\n",
      "Requirement already satisfied: sentencepiece>=0.1.94 in /usr/local/lib/python3.12/dist-packages (from detoxify) (0.2.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->detoxify) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->detoxify) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->detoxify) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->detoxify) (3.1.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2026.1.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.7.0->detoxify) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.7.0->detoxify) (3.0.3)\n",
      "Downloading detoxify-0.5.2-py3-none-any.whl (12 kB)\n",
      "Installing collected packages: detoxify\n",
      "Successfully installed detoxify-0.5.2\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
   ],
   "metadata": {
    "id": "RTDCmtA1xE3k"
   },
   "id": "RTDCmtA1xE3k",
   "execution_count": 68,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model_name = \"unitary/toxic-bert\"\n",
    "tok = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "model.eval()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 976,
     "referenced_widgets": [
      "f87edad4ae68485ba0c9e6725bdd53a8",
      "de94c9a3cd6d462da48397cc6ddc994d",
      "f4a6533f1bcb40398ec9daa8fe7595e3",
      "6f1c235ef47942bab896711c8ee09308",
      "30a2be7fed114a78a6dc7859fb9dc310",
      "255e077197654f08b6fd49029eed2f9e",
      "7c45ba3713d94001a2798ce55e4dc33e",
      "4b399a7522a643d19d56fb0638f0e198",
      "b4c105732b584e5ba61c9a1c52f3ce53",
      "fddbf10f447847c9810d260474150907",
      "410e81a9cf834ee4b3802e4a48314022",
      "f555e69578a24506934f9e1226516c2b",
      "2ede6644a81f4c7984667115dded6cec",
      "12a20c2ef42a4ce0bbf9fd2b9073b55d",
      "474fe2a5965247cea2988030824271df",
      "d893927c0c964dae961c1e1a7b34f7ec",
      "c10d633ba7c74beaa3b26d98e59cb2f4",
      "b152212dc1d846a19c6616d4df678d2a",
      "4f54ab42d57b442cab0ef5497d01d0d5",
      "2e6f3fdf9900490399f1c1d11f8b12fd",
      "33d5b7100a7347beb82ef609ba79c142",
      "4d6cd7d360234bd2bc25519d4bbf5c4d",
      "21d091b335a94fa88c84ddd5532b702a",
      "e004d39d288347969199fba00ce5aa81",
      "2e07d513447c4694a2f4c2ed930d07fd",
      "ffd90daccd954d36abaaa500fb731a10",
      "d37cc9e3e12f453e97284c455b51c738",
      "351ce1a83f75419ea3b8b8746cd5c218",
      "378339e842d94c2aa9f5b3a28755912a",
      "e954d04cdf6749aa83b33777335b9d2d",
      "f17cd84a44c342f2a5ccda86a83bf199",
      "b18cda3df27b492cbde2c267bff99ae5",
      "9d159b04aff04f01a2965eaabc0d3073",
      "6e334f58e8b844939753d373fb6b3a83",
      "b9dd2b71643447c7921cca87034b851d",
      "da1c2245424b46799b85b00f69c5f65a",
      "5588c50a496d4f5b82ea52c1291b7450",
      "939a50edc6f24d0ab263d65f675cf8b6",
      "04cda30d9e3d481e989152e277fb45aa",
      "b2e828b329d347b59301fb6ae3cd772b",
      "8546910dd80d4a5fa5d4b6f4e085ad14",
      "169ae6805ae144a08b44fb3b5bd2d6fc",
      "ddbe07328966401faca19fed80ebf53c",
      "ac6729b57f54416fb5c45613df9913bc",
      "a90ab06026c846ecb1d2afb9192d3311",
      "1172bbadf6c04c2eae83051d7096976a",
      "c30491bdbc7b45419af112983c229ae6",
      "c9b0d2d15abd4b6da2d98f4e89f4b411",
      "bf72316b330e40dcaa96e57c8ccc1ea4",
      "5a5f74a8a9b0435c97d2b81c055c8782",
      "75193fc971eb4471887edc610cf50019",
      "25d10d8cc75048c584b30fde3e8a1d7f",
      "bd32b6b4d2a646a68dc5cae89cba7834",
      "7deba2f5096e4ba09a1a24c781a6731d",
      "e066c0f37bdd497ba27341a0546ac0d3"
     ]
    },
    "collapsed": true,
    "id": "iY-V-5PlxD1e",
    "outputId": "054f4a49-bc4a-4035-e20d-9800e4ab14ca"
   },
   "id": "iY-V-5PlxD1e",
   "execution_count": 69,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/174 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f87edad4ae68485ba0c9e6725bdd53a8"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/811 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f555e69578a24506934f9e1226516c2b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "21d091b335a94fa88c84ddd5532b702a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6e334f58e8b844939753d373fb6b3a83"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a90ab06026c846ecb1d2afb9192d3311"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 69
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def toxicbert_predict(texts):\n",
    "    inputs = tok(texts, padding=True, truncation=True, return_tensors=\"pt\", max_length=128)\n",
    "    with torch.no_grad():\n",
    "        outs = model(**inputs).logits.squeeze(-1)\n",
    "        probs = torch.sigmoid(outs).numpy()\n",
    "    return probs"
   ],
   "metadata": {
    "id": "_IJdAU9kxGbJ"
   },
   "id": "_IJdAU9kxGbJ",
   "execution_count": 70,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "probs = []\n",
    "batch_size = 32\n",
    "for i in range(0, len(X_test), batch_size):\n",
    "    batch = X_test[i:i+batch_size]\n",
    "    probs.extend(toxicbert_predict(batch))\n",
    "\n",
    "roc_toxicbert = roc_auc_score(y_test, probs)\n",
    "print(\"Toxic-BERT ROC-AUC:\", roc_toxicbert)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426
    },
    "id": "9NNq1ztow6vl",
    "outputId": "e7261b67-8d1a-457d-c43a-a9d54461fe48"
   },
   "id": "9NNq1ztow6vl",
   "execution_count": 71,
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "text input must be of type `str` (single example), `list[str]` (batch or single pretokenized example) or `list[list[str]]` (batch of pretokenized examples).",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-1102991474.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mprobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoxicbert_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mroc_toxicbert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipython-input-652708339.py\u001b[0m in \u001b[0;36mtoxicbert_predict\u001b[0;34m(texts)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtoxicbert_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtok\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   3071\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_target_context_manager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3072\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_switch_to_input_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3073\u001b[0;31m             \u001b[0mencodings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_pair\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mall_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3074\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtext_target\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_switch_to_target_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m_call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m   3131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3132\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_valid_text_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3133\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   3134\u001b[0m                 \u001b[0;34m\"text input must be of type `str` (single example), `list[str]` (batch or single pretokenized example) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3135\u001b[0m                 \u001b[0;34m\"or `list[list[str]]` (batch of pretokenized examples).\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: text input must be of type `str` (single example), `list[str]` (batch or single pretokenized example) or `list[list[str]]` (batch of pretokenized examples)."
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def bert_latency(model, tokenizer, texts, n_runs=1000):\n",
    "    import time\n",
    "    times = []\n",
    "    for i in range(n_runs):\n",
    "        text = texts[i % len(texts)]\n",
    "        start = time.perf_counter()\n",
    "        _ = model(**tokenizer(text, return_tensors=\"pt\"))\n",
    "        times.append(time.perf_counter() - start)\n",
    "    times = np.array(times) * 1000\n",
    "    return {\n",
    "        \"mean_ms\": times.mean(),\n",
    "        \"p95_ms\": np.percentile(times, 95),\n",
    "        \"throughput_msg_s\": 1000 / times.mean(),\n",
    "    }\n",
    "\n",
    "lat_toxicbert = bert_latency(model, tok, X_test[:1000])\n",
    "print(lat_toxicbert)"
   ],
   "metadata": {
    "id": "Eo6fbhH2xJI0"
   },
   "id": "Eo6fbhH2xJI0",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# test of autofix nb"
   ],
   "metadata": {
    "id": "Zhrkr3Fg_zWs"
   },
   "id": "Zhrkr3Fg_zWs",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}